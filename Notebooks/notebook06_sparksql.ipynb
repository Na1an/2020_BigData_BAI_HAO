{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:22:18.185926Z",
     "start_time": "2020-03-27T09:22:18.181580Z"
    }
   },
   "outputs": [],
   "source": [
    "import jedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:22:32.576946Z",
     "start_time": "2020-03-27T09:22:28.376211Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"Spark SQL Course\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark SQL Course\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T13:26:29.707124Z",
     "start_time": "2020-02-04T13:26:29.703404Z"
    }
   },
   "source": [
    "# `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:31:43.170242Z",
     "start_time": "2020-03-27T09:31:43.162059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "row1 = Row(name=\"John\", age=21)\n",
    "row2 = Row(name=\"James\", age=32)\n",
    "row3 = Row(name=\"Jane\", age=18)\n",
    "row1['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:31:43.814757Z",
     "start_time": "2020-03-27T09:31:43.786715Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([row1, row2, row3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:31:44.345444Z",
     "start_time": "2020-03-27T09:31:44.338982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, name: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:22:48.004158Z",
     "start_time": "2020-03-27T09:22:47.958956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:22:50.465165Z",
     "start_time": "2020-03-27T09:22:48.353935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 21| John|\n",
      "| 32|James|\n",
      "| 18| Jane|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:36:01.730425Z",
     "start_time": "2020-03-27T09:36:01.724034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4) MapPartitionsRDD[99] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[98] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[97] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[96] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[95] at map at SerDeUtil.scala:137 []\n",
      " |  MapPartitionsRDD[94] at mapPartitions at SerDeUtil.scala:184 []\n",
      " |  PythonRDD[93] at RDD at PythonRDD.scala:53 []\n",
      " |  ParallelCollectionRDD[92] at parallelize at PythonRDD.scala:195 []\n"
     ]
    }
   ],
   "source": [
    "print(df.rdd.toDebugString().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:36:00.502937Z",
     "start_time": "2020-03-27T09:36:00.482939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:23:19.644870Z",
     "start_time": "2020-03-27T09:23:19.298977Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "|age|gender|  name|\n",
      "+---+------+------+\n",
      "| 21|  male|  John|\n",
      "| 25|female| James|\n",
      "| 46|  male|Albert|\n",
      "| 56|  male|Caesar|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create DataFrame from Row object\n",
    "rows = [\n",
    "    Row(name=\"John\", age=21, gender=\"male\"),\n",
    "    Row(name=\"James\", age=25, gender=\"female\"),\n",
    "    Row(name=\"Albert\", age=46, gender=\"male\"),\n",
    "    Row(**{'name': \"Caesar\", 'age': 56, 'gender': 'male'})\n",
    "]\n",
    "df = spark.createDataFrame(rows)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:41:51.540630Z",
     "start_time": "2020-03-27T09:41:51.303013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "|  Jane| 33|  null|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create DataFrame from Python List\n",
    "\n",
    "#column names\n",
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "\n",
    "#données\n",
    "rows = [\n",
    "    [\"John\", 21, \"male\"],\n",
    "    [\"James\", 25, \"female\"],\n",
    "    [\"Albert\", 46, \"male\"], \n",
    "    [\"Jane\", 33, None]\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(rows, column_names)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:23:24.864975Z",
     "start_time": "2020-03-27T09:23:24.858305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:42:41.512453Z",
     "start_time": "2020-03-27T09:42:41.167283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create DataFrame from RDD\n",
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "\n",
    "rdd = sc.parallelize([\n",
    "    (\"John\", 21, \"male\"),\n",
    "    (\"James\", 25, \"female\"),\n",
    "    (\"Albert\", 46, \"male\")\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(rdd, column_names)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:42:53.871148Z",
     "start_time": "2020-03-27T09:42:53.834903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 21, 'male'), ('James', 25, 'female'), ('Albert', 46, 'male')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:50:06.900186Z",
     "start_time": "2020-03-27T09:50:06.894579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(name,StringType,true),StructField(age,LongType,true),StructField(gender,StringType,true)))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:50:08.737975Z",
     "start_time": "2020-03-27T09:50:08.729148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:50:54.004100Z",
     "start_time": "2020-03-27T09:50:53.765790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When creating a DataFrame, the schema can be either inferred or defined by the user\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "rows = [(\"John\", 21, \"male\")]\n",
    "\n",
    "#rows, python list, 数据放首位， 列名放第二个\n",
    "df = spark.createDataFrame(rows, schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:24:10.204875Z",
     "start_time": "2020-03-27T09:24:09.747880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/polynote/notebooks/Notebooks\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/opt/polynote/notebooks/Notebooks/gro.csv.gz')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pwd\n",
    "from pathlib import Path\n",
    "import os\n",
    "dirpath = Path(os.getcwd())\n",
    "dirpath.joinpath('gro.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:37:14.975799Z",
     "start_time": "2020-03-27T10:37:14.742047Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'true')\n",
    "    .option('sep', \";\")\n",
    "    .load('gro.csv.gz')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:37:18.312300Z",
     "start_time": "2020-03-27T10:37:18.307310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id_Customer: string (nullable = true)\n",
      " |-- Y: string (nullable = true)\n",
      " |-- Customer_Type: string (nullable = true)\n",
      " |-- BirthDate: string (nullable = true)\n",
      " |-- Customer_Open_Date: string (nullable = true)\n",
      " |-- P_Client: string (nullable = true)\n",
      " |-- Educational_Level: string (nullable = true)\n",
      " |-- Marital_Status: string (nullable = true)\n",
      " |-- Number_Of_Dependant: string (nullable = true)\n",
      " |-- Years_At_Residence: string (nullable = true)\n",
      " |-- Net_Annual_Income: string (nullable = true)\n",
      " |-- Years_At_Business: string (nullable = true)\n",
      " |-- Prod_Sub_Category: string (nullable = true)\n",
      " |-- Prod_Decision_Date: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Type_Of_Residence: string (nullable = true)\n",
      " |-- Nb_Of_Products: string (nullable = true)\n",
      " |-- Prod_Closed_Date: string (nullable = true)\n",
      " |-- Prod_Category: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T09:25:01.677376Z",
     "start_time": "2020-03-27T09:25:01.670807Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "?date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:37:11.007644Z",
     "start_time": "2020-03-27T10:37:10.160504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+--------+----------+----------+\n",
      "|prod_id|      date|quantity|prod_cat|prod_brand|prod_value|\n",
      "+-------+----------+--------+--------+----------+----------+\n",
      "|      1|2017-11-01|       2|   mouse| microsoft|     39.99|\n",
      "|      1|2017-11-02|       1|   mouse| microsoft|     39.99|\n",
      "|      2|2017-11-05|       1|keyboard|  logitech|     59.99|\n",
      "+-------+----------+--------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "products = spark.createDataFrame([\n",
    "    ('1', 'mouse', 'microsoft', 39.99),\n",
    "    ('2', 'keyboard', 'logitech', 59.99),\n",
    "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
    "\n",
    "purchases = spark.createDataFrame([\n",
    "    (date(2017, 11, 1), 2, '1'),\n",
    "    (date(2017, 11, 2), 1, '1'),\n",
    "    (date(2017, 11, 5), 1, '2'),\n",
    "], ['date', 'quantity', 'prod_id'])\n",
    "\n",
    "# The default join type is the \"INNER\" join\n",
    "purchases.join(products, 'prod_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:37:25.417714Z",
     "start_time": "2020-03-27T10:37:24.640109Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+-------+--------+----------+----------+\n",
      "|      date|quantity|prod_id|prod_id|prod_cat|prod_brand|prod_value|\n",
      "+----------+--------+-------+-------+--------+----------+----------+\n",
      "|2017-11-01|       2|      1|      1|   mouse| microsoft|     39.99|\n",
      "|2017-11-02|       1|      1|      1|   mouse| microsoft|     39.99|\n",
      "|2017-11-05|       1|      2|      2|keyboard|  logitech|     59.99|\n",
      "+----------+--------+-------+-------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products.createOrReplaceTempView(\"products\")\n",
    "purchases.createOrReplaceTempView(\"purchases\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM\n",
    "(purchases AS prc INNER JOIN products AS prd \n",
    "on prc.prod_id = prd.prod_id)\n",
    "\"\"\"\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:40:53.345129Z",
     "start_time": "2020-03-27T10:40:53.134717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+----------+----+\n",
      "|prod_id|prod_cat|prod_brand|prod_value|mise|\n",
      "+-------+--------+----------+----------+----+\n",
      "|      1|   mouse| microsoft|     39.99|10.0|\n",
      "|      2|keyboard|  logitech|     59.99|20.0|\n",
      "+-------+--------+----------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products.withColumn(\"mise\", products.prod_id*10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:04:45.293715Z",
     "start_time": "2020-03-27T10:04:45.242104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [prod_id#246, date#244, quantity#245L, prod_cat#237, prod_brand#238, prod_value#239]\n",
      "+- *(5) SortMergeJoin [prod_id#246], [prod_id#236], Inner\n",
      "   :- *(2) Sort [prod_id#246 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(prod_id#246, 200)\n",
      "   :     +- *(1) Filter isnotnull(prod_id#246)\n",
      "   :        +- Scan ExistingRDD[date#244,quantity#245L,prod_id#246]\n",
      "   +- *(4) Sort [prod_id#236 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(prod_id#236, 200)\n",
      "         +- *(3) Filter isnotnull(prod_id#236)\n",
      "            +- Scan ExistingRDD[prod_id#236,prod_cat#237,prod_brand#238,prod_value#239]\n"
     ]
    }
   ],
   "source": [
    "purchases.join(products, 'prod_id').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:05:06.947288Z",
     "start_time": "2020-03-27T10:05:05.478226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+-------+--------+----------+----------+\n",
      "|      date|quantity|prod_id_x|prod_id|prod_cat|prod_brand|prod_value|\n",
      "+----------+--------+---------+-------+--------+----------+----------+\n",
      "|2017-11-02|       1|        3|   null|    null|      null|      null|\n",
      "|2017-11-01|       2|        1|      1|   mouse| microsoft|     39.99|\n",
      "+----------+--------+---------+-------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_purchases = spark.createDataFrame([\n",
    "    (date(2017, 11, 1), 2, '1'),\n",
    "    (date(2017, 11, 2), 1, '3'),\n",
    "], ['date', 'quantity', 'prod_id_x'])\n",
    "\n",
    "# The default join type is the \"INNER\" join\n",
    "join_rule = new_purchases.prod_id_x == products.prod_id\n",
    "new_purchases.join(products, join_rule, 'left').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T11:23:11.811592Z",
     "start_time": "2020-03-03T11:23:10.434135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+-------+--------+----------+----------+\n",
      "|      date|quantity|prod_id_x|prod_id|prod_cat|prod_brand|prod_value|\n",
      "+----------+--------+---------+-------+--------+----------+----------+\n",
      "|2017-11-02|       1|        3|   null|    null|      null|      null|\n",
      "|2017-11-01|       2|        1|      1|   mouse| microsoft|     39.99|\n",
      "+----------+--------+---------+-------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_purchases = spark.createDataFrame([\n",
    "    (date(2017, 11, 1), 2, '1'),\n",
    "    (date(2017, 11, 2), 1, '3'),\n",
    "], ['date', 'quantity', 'prod_id_x'])\n",
    "\n",
    "# The default join type is the \"INNER\" join\n",
    "join_rule = new_purchases.prod_id_x == products.prod_id\n",
    "new_purchases.join(products, join_rule, 'left').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various types of joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:05:55.813927Z",
     "start_time": "2020-03-27T10:05:55.438670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  1|   A1|\n",
      "|  2|   A2|\n",
      "|  3|   A3|\n",
      "|  4|   A4|\n",
      "+---+-----+\n",
      "\n",
      "RIGHT\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  3|   A3|\n",
      "|  4|   A4|\n",
      "|  4| A4_1|\n",
      "|  5|   A5|\n",
      "|  6|   A6|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "left = spark.createDataFrame([\n",
    "    (1, \"A1\"), (2, \"A2\"), (3, \"A3\"), (4, \"A4\")], \n",
    "    [\"id\", \"value\"])\n",
    "\n",
    "right = spark.createDataFrame([\n",
    "    (3, \"A3\"), (4, \"A4\"), (4, \"A4_1\"), (5, \"A5\"), (6, \"A6\")], \n",
    "    [\"id\", \"value\"])\n",
    "\n",
    "print(\"LEFT\")\n",
    "left.orderBy(\"id\").show()\n",
    "\n",
    "print(\"RIGHT\")\n",
    "right.orderBy(\"id\").show()\n",
    "\n",
    "join_types = [\n",
    "    \"inner\", \"outer\", \"left\", \"right\",\n",
    "    \"leftsemi\", \"leftanti\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T10:06:06.003191Z",
     "start_time": "2020-03-27T10:05:59.525929Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner\n",
      "+---+-----+-----+\n",
      "| id|value|value|\n",
      "+---+-----+-----+\n",
      "|  3|   A3|   A3|\n",
      "|  4|   A4|   A4|\n",
      "|  4|   A4| A4_1|\n",
      "+---+-----+-----+\n",
      "\n",
      "outer\n",
      "+---+-----+-----+\n",
      "| id|value|value|\n",
      "+---+-----+-----+\n",
      "|  1|   A1| null|\n",
      "|  2|   A2| null|\n",
      "|  3|   A3|   A3|\n",
      "|  4|   A4|   A4|\n",
      "|  4|   A4| A4_1|\n",
      "|  5| null|   A5|\n",
      "|  6| null|   A6|\n",
      "+---+-----+-----+\n",
      "\n",
      "left\n",
      "+---+-----+-----+\n",
      "| id|value|value|\n",
      "+---+-----+-----+\n",
      "|  1|   A1| null|\n",
      "|  2|   A2| null|\n",
      "|  3|   A3|   A3|\n",
      "|  4|   A4|   A4|\n",
      "|  4|   A4| A4_1|\n",
      "+---+-----+-----+\n",
      "\n",
      "right\n",
      "+---+-----+-----+\n",
      "| id|value|value|\n",
      "+---+-----+-----+\n",
      "|  3|   A3|   A3|\n",
      "|  4|   A4|   A4|\n",
      "|  4|   A4| A4_1|\n",
      "|  5| null|   A5|\n",
      "|  6| null|   A6|\n",
      "+---+-----+-----+\n",
      "\n",
      "leftsemi\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  3|   A3|\n",
      "|  4|   A4|\n",
      "+---+-----+\n",
      "\n",
      "leftanti\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  1|   A1|\n",
      "|  2|   A2|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for join_type in join_types:\n",
    "    print(join_type)\n",
    "    left.join(right, on=\"id\", how=join_type)\\\n",
    "        .orderBy(\"id\")\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271.2604064941406px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
